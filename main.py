import streamlit as st
import google.generativeai as genai
import json
import os
import uuid
import time
from datetime import datetime
from PIL import Image
import io
import base64
import speech_recognition as sr
from gtts import gTTS
import tempfile
from pydub import AudioSegment 

# --- 1. SAYFA AYARLARI ---
st.set_page_config(
    page_title="BAUN-MYO Asistan", 
    page_icon="üéì",  
    layout="centered",
    initial_sidebar_state="expanded"
)

# --- 2. TASARIM (CSS) ---
custom_style = """
<style>
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap');
html, body, [class*="css"] {font-family: 'Inter', sans-serif;}
footer {visibility: hidden;}
header {background-color: transparent !important;}
.stApp {background-color: #0e1117;}
section[data-testid="stSidebar"] {background-color: #161b22 !important; border-right: 1px solid #30363d;}
[data-testid="stSidebar"] h1, [data-testid="stSidebar"] h2, [data-testid="stSidebar"] h3 {color: #c9d1d9 !important;}
.stButton button {border: 1px solid #30363d; border-radius: 8px; background-color: #21262d; color: #c9d1d9; transition: all 0.3s ease;}
.stButton button:hover {background-color: #30363d; border-color: #8b949e; color: white;}
[data-testid="stChatMessage"]:nth-of-type(odd) {background-color: #21262d; border: 1px solid #30363d; border-radius: 0px 20px 20px 20px; padding: 15px; margin-bottom: 10px;}
[data-testid="stChatMessage"]:nth-of-type(even) {background-color: #1f6feb; color: white; border-radius: 20px 0px 20px 20px; padding: 15px; margin-bottom: 10px; border: none;}
[data-testid="stChatMessage"]:nth-of-type(even) * {color: white !important;}
.stChatInputContainer textarea {background-color: #161b22; color: white; border: 1px solid #30363d; border-radius: 12px;}
</style>
"""
st.markdown(custom_style, unsafe_allow_html=True)

# --- 3. KLAS√ñR VE TEMƒ∞ZLƒ∞K ---
SESSION_FOLDER = "sessions"
if not os.path.exists(SESSION_FOLDER):
    os.makedirs(SESSION_FOLDER)

def temizlik_yap(dakika=30):
    su_an = time.time()
    try:
        for dosya in os.listdir(SESSION_FOLDER):
            if dosya.endswith(".json"):
                dosya_yolu = os.path.join(SESSION_FOLDER, dosya)
                if (su_an - os.path.getmtime(dosya_yolu)) > (dakika * 60):
                    try: os.remove(dosya_yolu)
                    except: pass
    except: pass

temizlik_yap(dakika=30)

# --- 4. SESSION STATE BA≈ûLATMA ---
if "session_id" not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())

if "messages" not in st.session_state:
    st.session_state.messages = []

if "audio_processed" not in st.session_state:
    st.session_state.audio_processed = False

if "last_audio_hash" not in st.session_state:
    st.session_state.last_audio_hash = None

USER_HISTORY_FILE = os.path.join(SESSION_FOLDER, f"history_{st.session_state.session_id}.json")

# --- 5. API VE Bƒ∞LGƒ∞ BANKASI ---
def bilgi_bankasini_oku():
    dosya_yolu = "bilgi.txt"
    varsayilan = "Sen bir yapay zeka asistanƒ±sƒ±n."
    if os.path.exists(dosya_yolu):
        try:
            with open(dosya_yolu, "r", encoding="utf-8") as f:
                return f.read()
        except: return varsayilan
    return varsayilan

okul_bilgisi = bilgi_bankasini_oku()

system_instruction = f"""
{okul_bilgisi}

EKSTRA G√ñREV (G√ñRSEL OLU≈ûTURMA):
Eƒüer kullanƒ±cƒ± senden a√ßƒ±k√ßa bir g√∂rsel, resim, fotoƒüraf veya √ßizim olu≈üturmanƒ± isterse, normal bir cevap verme.
Bunun yerine, cevabƒ±nƒ±n ba≈üƒ±na tam olarak ≈üu etiketi koy: `[GORSEL_OLUSTUR]`
Bu etiketin hemen ardƒ±ndan, kullanƒ±cƒ±nƒ±n istediƒüi g√∂rseli detaylƒ± bir ≈üekilde tarif eden ƒ∞NGƒ∞Lƒ∞ZCE bir prompt yaz.
√ñrnek: `[GORSEL_OLUSTUR] A photorealistic image of Balikesir University campus.`
"""

try:
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel(model_name='gemini-2.0-flash', system_instruction=system_instruction)
    imagen_model = genai.GenerativeModel("imagen-3.0-generate-001")
except Exception as e:
    st.error(f"API Hatasƒ±: {e}")
    st.stop()

# --- 6. YARDIMCI FONKSƒ∞YONLAR ---
def load_history():
    if not os.path.exists(USER_HISTORY_FILE):
        return []
    try:
        with open(USER_HISTORY_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except:
        return []

def save_history(history):
    with open(USER_HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=4)

def image_to_base64(image):
    try:
        buffered = io.BytesIO()
        image.save(buffered, format="PNG")
        return base64.b64encode(buffered.getvalue()).decode()
    except: return None

def base64_to_image(base64_str):
    try:
        if base64_str: return Image.open(io.BytesIO(base64.b64decode(base64_str)))
    except: return None

def get_audio_hash(audio_bytes):
    """Ses dosyasƒ±nƒ±n hash'ini olu≈ütur (tekrar i≈ülemeyi √∂nlemek i√ßin)"""
    import hashlib
    return hashlib.md5(audio_bytes).hexdigest()

# --- SES Gƒ∞Rƒ∞≈ûƒ∞ (LOOP SORUNU D√úZELTƒ∞LDƒ∞) ---
def sesten_yaziya(audio_bytes):
    """iPhone Safari'den gelen webm/opus formatƒ±nƒ± i≈üler"""
    r = sr.Recognizer()
    
    with tempfile.NamedTemporaryFile(delete=False, suffix=".webm") as tmp_input:
        tmp_input.write(audio_bytes)
        tmp_input_path = tmp_input.name
    
    tmp_wav_path = tmp_input_path.replace(".webm", ".wav")

    try:
        audio = AudioSegment.from_file(tmp_input_path, format="webm")
        audio = audio.set_channels(1)
        audio = audio.set_frame_rate(16000)
        audio.export(tmp_wav_path, format="wav")
        
        with sr.AudioFile(tmp_wav_path) as source:
            r.adjust_for_ambient_noise(source, duration=0.5)
            audio_data = r.record(source)
            text = r.recognize_google(audio_data, language="tr-TR")
            return text
            
    except sr.UnknownValueError:
        return None
    except sr.RequestError as e:
        st.error(f"‚ùå Google Speech API hatasƒ±: {e}")
        return None
    except Exception as e:
        st.error(f"‚ùå Ses i≈üleme hatasƒ±: {e}")
        return None
        
    finally:
        try:
            if os.path.exists(tmp_input_path): 
                os.unlink(tmp_input_path)
            if os.path.exists(tmp_wav_path): 
                os.unlink(tmp_wav_path)
        except:
            pass

# --- SES OLU≈ûTURMA ---
def metni_sese_cevir_bytes(text):
    try:
        tts = gTTS(text=text, lang='tr', slow=False)
        fp = io.BytesIO()
        tts.write_to_fp(fp)
        fp.seek(0)
        return fp
    except Exception as e:
        st.error(f"Ses olu≈üturma hatasƒ±: {e}")
        return None

# --- G√ñRSEL OLU≈ûTURMA ---
def gorsel_olustur(prompt_text):
    try:
        result = imagen_model.generate_images(
            prompt=prompt_text,
            number_of_images=1,
            aspect_ratio="1:1",
            safety_filter_level="block_few",
            person_generation="allow_adult"
        )
        if result and result.images:
             image_data = result.images[0].image_bytes
             img = Image.open(io.BytesIO(image_data))
             return img, None
        else:
             return None, "Model g√∂rsel √ºretemedi."
    except Exception as e:
        return None, str(e)

# --- 7. SIDEBAR ---
with st.sidebar:
    st.title("BAUN MYO")
    st.markdown("---")
    st.subheader("ƒ∞≈ülemler")
    
    uploaded_file = st.file_uploader("G√∂rsel Y√ºkle", type=["jpg", "png", "jpeg"])
    current_image = None
    if uploaded_file:
        try:
            current_image = Image.open(uploaded_file)
            st.success("‚úÖ G√∂rsel y√ºklendi.")
            st.image(current_image, use_container_width=True)
        except: 
            st.error("‚ùå G√∂rsel y√ºklenemedi")
            
    st.markdown("---")
    ses_aktif = st.toggle("üé§ Sesli Yanƒ±t", value=False)
    
    if st.button("Yeni Sohbet", use_container_width=True):
        st.session_state.messages = []
        st.session_state.current_chat_id = str(uuid.uuid4())
        st.session_state.audio_processed = False
        st.session_state.last_audio_hash = None
        st.rerun()
        
    st.markdown("### Ge√ßmi≈ü")
    for chat in reversed(load_history()):
        raw_title = chat.get("title", "Sohbet")
        display_title = (raw_title[:20] + '..') if len(raw_title) > 20 else raw_title
        if st.button(f"üí¨ {display_title}", key=chat["id"], use_container_width=True):
            st.session_state.messages = chat["messages"]
            st.session_state.current_chat_id = chat["id"]
            st.session_state.audio_processed = False
            st.session_state.last_audio_hash = None
            st.rerun()
            
    st.markdown("---")
    if st.button("Temizle", type="primary", use_container_width=True):
        if os.path.exists(USER_HISTORY_FILE): os.remove(USER_HISTORY_FILE)
        st.session_state.messages = []
        st.session_state.audio_processed = False
        st.session_state.last_audio_hash = None
        st.rerun()

# --- 8. ANA EKRAN ---
st.markdown("<h1 style='text-align: center; color: white;'>BAUN-MYO AI Asistan</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align: center; color: gray;'>Balƒ±kesir Meslek Y√ºksekokulu AI Asistan.</p>", unsafe_allow_html=True)

# Mesajlarƒ± Ekrana Bas
for message in st.session_state.messages:
    avatar_icon = "üë§" if message["role"] == "user" else "ü§ñ"
    with st.chat_message(message["role"], avatar=avatar_icon):
        if message.get("image"):
            try:
                img = base64_to_image(message["image"])
                if img: st.image(img, width=400, caption="G√∂rsel")
            except: pass
        
        if message.get("content"):
             st.markdown(message["content"])

# --- 9. Gƒ∞Rƒ∞≈û ALANI (LOOP SORUNU D√úZELTƒ∞LDƒ∞) ---
prompt = None
audio_value = None

if ses_aktif:
    st.write("üéôÔ∏è **Ses Kaydƒ±:**")
    audio_value = st.audio_input("Konu≈ü")

text_input = st.chat_input("Mesajƒ±nƒ±zƒ± buraya yazƒ±n...")

# SES ƒ∞≈ûLEME (TEKRAR √ñNLEME MEKANƒ∞ZMASI)
if ses_aktif and audio_value and not st.session_state.audio_processed:
    audio_bytes = audio_value.read()
    if audio_bytes:
        current_hash = get_audio_hash(audio_bytes)
        
        # Aynƒ± ses dosyasƒ± daha √∂nce i≈ülendiyse i≈üleme
        if current_hash != st.session_state.last_audio_hash:
            with st.spinner("üîÑ Sesiniz i≈üleniyor..."):
                prompt = sesten_yaziya(audio_bytes)
                st.session_state.last_audio_hash = current_hash
                st.session_state.audio_processed = True
                
                if not prompt:
                    st.warning("‚ö†Ô∏è Ses anla≈üƒ±lamadƒ±. L√ºtfen tekrar deneyin.")
                    st.session_state.audio_processed = False
                    st.session_state.last_audio_hash = None
elif text_input:
    prompt = text_input
    # Metin giri≈üinde ses flag'ini sƒ±fƒ±rla
    st.session_state.audio_processed = False
    st.session_state.last_audio_hash = None

# --- 10. CEVAP √úRETME ---
if prompt:
    # Ses i≈üleme flag'ini sƒ±fƒ±rla (yeni kayƒ±t i√ßin hazƒ±r)
    if ses_aktif:
        st.session_state.audio_processed = False
    
    saved_image_base64 = None
    saved_image_for_api = None
    if current_image:
        saved_image_base64 = image_to_base64(current_image)
        saved_image_for_api = current_image.copy()
    
    with st.chat_message("user", avatar="üë§"):
        st.markdown(prompt)
        if saved_image_for_api: st.image(saved_image_for_api, width=300)
    
    st.session_state.messages.append({
        "role": "user", "content": prompt, "image": saved_image_base64
    })

    try:
        with st.spinner('ü§î Asistan d√º≈ü√ºn√ºyor...'):
            chat_history_text = []
            for m in st.session_state.messages[:-1]:
                msg_content = m.get("content", "")
                if msg_content is None: msg_content = "..."
                chat_history_text.append({
                    "role": "user" if m["role"] == "user" else "model",
                    "parts": [msg_content]
                })
            
            chat_session = model.start_chat(history=chat_history_text)
            
            if saved_image_for_api:
                response = chat_session.send_message([prompt, saved_image_for_api])
            else:
                response = chat_session.send_message(prompt)
            
            bot_reply_text = response.text

        generated_image_base64 = None
        final_content_text = bot_reply_text

        if bot_reply_text.strip().startswith("[GORSEL_OLUSTUR]"):
            imagen_prompt = bot_reply_text.replace("[GORSEL_OLUSTUR]", "").strip()
            
            with st.spinner('üé® G√∂rsel olu≈üturuluyor...'):
                generated_img, hata_mesaji = gorsel_olustur(imagen_prompt)
                
                if generated_img:
                    generated_image_base64 = image_to_base64(generated_img)
                    final_content_text = ""
                    with st.chat_message("assistant", avatar="ü§ñ"):
                        st.image(generated_img, width=400, caption="Olu≈üturulan G√∂rsel")
                else:
                    final_content_text = f"‚ö†Ô∏è G√∂rsel olu≈üturulamadƒ±: {hata_mesaji}"
                    with st.chat_message("assistant", avatar="ü§ñ"):
                        st.error(final_content_text)
        else:
            with st.chat_message("assistant", avatar="ü§ñ"):
                st.markdown(final_content_text)
                
                if ses_aktif and final_content_text:
                    with st.spinner("üîä Ses olu≈üturuluyor..."):
                        sound_fp = metni_sese_cevir_bytes(final_content_text)
                        if sound_fp:
                            audio_bytes = sound_fp.read()
                            
                            st.download_button(
                                label="üîä Yanƒ±tƒ± Sesli Dinle",
                                data=audio_bytes,
                                file_name=f"yanit.mp3",
                                mime="audio/mpeg",
                                use_container_width=True
                            )
                            
                            st.audio(audio_bytes, format='audio/mpeg')

        st.session_state.messages.append({
            "role": "assistant", "content": final_content_text, "image": generated_image_base64
        })
        
        current_history = load_history()
        chat_exists = False
        if "current_chat_id" not in st.session_state:
            st.session_state.current_chat_id = str(uuid.uuid4())
        
        cid = st.session_state.current_chat_id
        for chat in current_history:
            if chat["id"] == cid:
                chat["messages"] = st.session_state.messages
                chat_exists = True
                break
        
        if not chat_exists:
            title = prompt[:30] + "..." if len(prompt) > 30 else prompt
            current_history.append({
                "id": cid, "title": title, "timestamp": str(datetime.now()), "messages": st.session_state.messages
            })
        
        save_history(current_history)

    except Exception as e:
        st.error(f"‚ùå Bir hata olu≈ütu: {e}")